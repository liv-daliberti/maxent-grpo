"""
Copyright 2025 Liv d'Aliberti

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
"""

# Adapted from huggingface/transformers: https://github.com/huggingface/transformers/blob/21a2d900eceeded7be9edc445b56877b95eda4ca/setup.py


import re
import shutil
from pathlib import Path

from setuptools import find_packages, setup
from setuptools.command.install import install as _install
from setuptools.command.develop import develop as _develop
import importlib


def _patch_trl_vllm_serve():
    """
    Ensure TRL's vllm_serve.py passes use_tqdm_on_load=True to vLLM.LLM.

    We locate trl.scripts.vllm_serve, and if the LLM(...) call does not
    already include use_tqdm_on_load, we insert it after enforce_eager.
    """
    try:
        trl_mod = importlib.import_module("trl.scripts.vllm_serve")
        path = Path(trl_mod.__file__)
    except Exception as e:
        print(f"[open-r1 setup] Skipping TRL patch (import failed): {e}")
        return

    try:
        text = path.read_text(encoding="utf-8")
    except Exception as e:
        print(f"[open-r1 setup] Skipping TRL patch (read failed): {e}")
        return

    if "use_tqdm_on_load=True" in text:
        print("[open-r1 setup] TRL vllm_serve already patched (use_tqdm_on_load=True).")
        return

    # Preferred anchor to insert after
    anchor = "enforce_eager=script_args.enforce_eager,"
    insertion = "\n        use_tqdm_on_load=True,"

    if anchor in text:
        new_text = text.replace(anchor, anchor + insertion)
    else:
        # Fallback: try to place after dtype assignment
        alt_anchor = "dtype=script_args.dtype,"
        if alt_anchor in text:
            new_text = text.replace(alt_anchor, alt_anchor + insertion)
        else:
            # Last resort: after the opening of the LLM call
            llm_call = "llm = LLM("
            if llm_call in text:
                new_text = text.replace(llm_call, llm_call + insertion + "\n")
            else:
                print(
                    "[open-r1 setup] Could not find insertion point in TRL vllm_serve; skipping patch."
                )
                return

    try:
        path.write_text(new_text, encoding="utf-8")
        print(f"[open-r1 setup] Patched TRL vllm_serve at: {path}")
    except Exception as e:
        print(f"[open-r1 setup] Failed to write TRL patch: {e}")


class install(_install):
    def run(self):
        super().run()
        _patch_trl_vllm_serve()


class develop(_develop):
    def run(self):
        super().run()
        _patch_trl_vllm_serve()


# Remove stale open_r1.egg-info directories to avoid https://github.com/pypa/pip/issues/5466
repo_root = Path(__file__).parent
stale_egg_infos = [
    repo_root / "open_r1.egg-info",
    repo_root / "src" / "open_r1.egg-info",
]
for stale_egg_info in stale_egg_infos:
    if stale_egg_info.exists():
        print(
            (
                "Warning: {} exists.\n\n"
                "If you recently updated open_r1, this is expected,\n"
                "but it may prevent open_r1 from installing in editable mode.\n\n"
                "This directory is automatically generated by Python's packaging tools.\n"
                "I will remove it now.\n\n"
                "See https://github.com/pypa/pip/issues/5466 for details.\n"
            ).format(stale_egg_info)
        )
        shutil.rmtree(stale_egg_info)


# IMPORTANT: all dependencies should be listed here with their version requirements, if any.
#   * If a dependency is fast-moving (e.g. trl), pin to the exact version
_deps = [
    "accelerate==1.4.0",
    "bitsandbytes>=0.43.0",
    "datasets>=3.2.0",
    "deepspeed==0.16.8",
    "distilabel[vllm,ray,openai]>=1.5.2",
    "e2b-code-interpreter>=1.0.5",
    "einops>=0.8.0",
    "flake8>=6.0.0",
    "pylint>=3.2.0",
    "pre-commit>=3.8.0",
    "hf_transfer>=0.1.4",
    "huggingface-hub[cli,hf_xet]>=0.30.2,<1.0",
    "isort>=5.12.0",
    "jieba",  # Needed for Chinese language support
    "langdetect",  # Needed for LightEval's extended tasks
    "liger-kernel>=0.5.10",
    "lighteval @ git+https://github.com/huggingface/lighteval.git@d3da6b9bbf38104c8b5e1acc86f83541f9a502d1",  # Critical bug fix for tokenizer revisions
    "morphcloud==0.1.67",
    "packaging>=23.0",
    "parameterized>=0.9.0",
    "peft>=0.14.0",
    "pytest",
    "python-dotenv",
    "ruff>=0.9.0",
    "safetensors>=0.3.3",
    "sentencepiece>=0.1.99",
    "torch==2.6.0",
    "transformers==4.52.3",
    "trl[vllm]==0.18.0",
    "wandb>=0.19.1",
    "async-lru>=2.0.5",
    "aiofiles>=24.1.0",
    "pandas>=2.2.3",
    "sphinx>=7.2",
    "sphinx-rtd-theme>=1.3",
    "myst-parser",
    "sphinx-copybutton",
    "sphinx-design",
    "linkify-it-py",
    "mdurl",
    "omegaconf>=2.3.0",
    "hydra-core>=1.3.2",
    "typer>=0.12.5",
]

# this is a lookup table with items like:
#
# tokenizers: "tokenizers==0.9.4"
# packaging: "packaging"
#
# some of the values are versioned whereas others aren't.
deps = {
    b: a
    for a, b in (
        re.findall(r"^(([^!=<>~ \[\]]+)(?:\[[^\]]+\])?(?:[!=<>~ ].*)?$)", x)[0]
        for x in _deps
    )
}


def deps_list(*pkgs):
    return [deps[pkg] for pkg in pkgs]


extras = {}
extras["tests"] = deps_list("pytest", "parameterized", "jieba")
extras["torch"] = deps_list("torch")
extras["quality"] = deps_list("ruff", "isort", "flake8", "pylint", "pre-commit")
extras["docs"] = deps_list("sphinx", "sphinx-rtd-theme")
extras["code"] = deps_list(
    "e2b-code-interpreter", "python-dotenv", "morphcloud", "jieba", "pandas", "aiofiles"
)
extras["eval"] = deps_list("lighteval")
extras["dev"] = (
    extras["quality"]
    + extras["tests"]
    + extras["eval"]
    + extras["code"]
    + extras["docs"]
)

# core dependencies shared across the whole project - keep this to a bare minimum :)
install_requires = [
    deps["accelerate"],
    deps["bitsandbytes"],
    deps["einops"],
    deps["datasets"],
    deps["deepspeed"],
    deps["hf_transfer"],
    deps["huggingface-hub"],
    deps["langdetect"],
    deps["liger-kernel"],
    deps["packaging"],  # utilities from PyPA to e.g., compare versions
    deps["safetensors"],
    deps["sentencepiece"],
    deps["transformers"],
    deps["trl"],
    deps["wandb"],
    deps["async-lru"],
    deps["typer"],
    deps["omegaconf"],
    deps["hydra-core"],
]


# Long description from README if present
readme_path = repo_root / "README.md"
if readme_path.exists():
    long_description = readme_path.read_text(encoding="utf-8")
else:
    long_description = "Open R1"


setup(
    name="open-r1",
    version="0.1.0.dev0",  # expected format is one of x.y.z.dev0, or x.y.z.rc1 or x.y.z (no to dashes, yes to dots)
    author="The Hugging Face team (past and future)",
    author_email="lewis@huggingface.co",
    description="Open R1",
    long_description=long_description,
    long_description_content_type="text/markdown",
    keywords="llm inference-time compute reasoning",
    license="Apache-2.0",
    url="https://github.com/huggingface/open-r1",
    package_dir={"": "src"},
    packages=find_packages("src"),
    zip_safe=False,
    cmdclass={
        "install": install,
        "develop": develop,
    },
    extras_require=extras,
    python_requires=">=3.10.9",
    install_requires=install_requires,
    entry_points={
        "console_scripts": [
            "maxent-grpo=cli.hydra_cli:hydra_entry",
            "maxent-grpo-baseline=cli.hydra_cli:baseline_entry",
            "maxent-grpo-maxent=cli.hydra_cli:maxent_entry",
            "maxent-grpo-generate=cli.hydra_cli:generate_entry",
            "maxent-grpo-inference=cli.hydra_cli:inference_entry",
        ],
    },
    classifiers=[
        "Development Status :: 3 - Alpha",
        "Intended Audience :: Developers",
        "Intended Audience :: Education",
        "Intended Audience :: Science/Research",
        "License :: OSI Approved :: Apache Software License",
        "Operating System :: OS Independent",
        "Programming Language :: Python :: 3",
        "Programming Language :: Python :: 3.10",
        "Topic :: Scientific/Engineering :: Artificial Intelligence",
    ],
)
