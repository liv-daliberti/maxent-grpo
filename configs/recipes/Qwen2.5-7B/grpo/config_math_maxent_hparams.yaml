# Copyright 2025 Liv d'Aliberti
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# GRPO-only math recipe that mirrors the MaxEnt math hyperparameters
# (same batch size, logging, KL control, prompt lengths, etc.) but
# leaves MaxEnt weighting disabled. Intended for 7B comparisons.

# Model arguments
model_name_or_path: Qwen/Qwen2.5-7B
model_revision: main
resume_from_checkpoint: true
torch_dtype: float16
attn_implementation: sdpa

# Data training arguments
dataset_name: open-r1/OpenR1-Math-220k
dataset_prompt_column: problem
eval_dataset_name: HuggingFaceH4/MATH-500
eval_dataset_split: test
eval_dataset_prompt_column: problem
eval_dataset_solution_column: answer
disable_distributed_sampler: true
system_prompt: |
  You are an expert *mathematics problem-solver*.

  Every time you receive a problem you must:
  • Analyse it thoroughly.
    – Pinpoint the **goal** (what quantity/set/form is requested).
    – Pinpoint the **givens/constraints** (domains, integrality, non-negativity, geometric conditions).
    – Choose the **methods** to apply (algebraic manipulation, factorization, inequalities, counting, modular arithmetic, geometry, calculus, etc.).
    – Write out the full derivation that leads to the final result.

  • Check that the result satisfies all original constraints (no extraneous roots, correct domain, simplified form, exact arithmetic).

  • Respond in **exactly** the tag-based format shown below – no greeting, no commentary outside the tags.
    – The final answer goes inside `<answer>` **only**.
    – Use **exact** math (fractions, radicals, π, e). Avoid unnecessary decimals.
    – Canonical forms: integers as plain numbers; reduced fractions a/b with b>0; simplified radicals; rationalized denominators; sets/tuples with standard notation; intervals in standard notation.

  ------------------------------------------------------------
  TAG TEMPLATE (copy this shape for every problem)
  <think>
  YOUR reasoning process goes here:
  1. quote the relevant bits of the problem
  2. name the mathematical tool(s) you apply
  3. show each intermediate step until the result is reached

  If you spot an error or an unmet constraint, iterate, repeating steps 1–3 as many
  times as necessary until you are confident in your result. Finish by verifying the
  result satisfies the original conditions exactly (substitution/checks).
  </think>
  <answer>
  THEANSWER
  </answer>

# GRPO trainer config (MaxEnt disabled)
train_grpo_objective: true
bf16: true
fp16: false
vllm_mode: server         # reuse the single vLLM server from the launcher
vllm_return_logprobs: true
vllm_gpu_memory_utilization: 0.9
do_eval: true
gradient_accumulation_steps: 128
gradient_checkpointing: true
gradient_checkpointing_kwargs:
  use_reentrant: false
gen_temperature: 1.0          # paper setting
gen_top_p: 1.0
gen_top_k: 0
gen_best_of: 1
vllm_stop_sequences:
  - "</answer>"
  - "</answer>\n"
  - "</assistant>"
vllm_request_timeout: 600
hub_model_id: od2961/Qwen2.5-7B-Open-R1-GRPO-math-2k
hub_strategy: every_save
learning_rate: 1e-6
adam_beta2: 0.99
adam_epsilon: 1e-06
log_completions: true
log_level: info
logging_first_step: true
logging_steps: 1
logging_strategy: steps
lr_scheduler_type: cosine
max_prompt_length: 2096
max_completion_length: 4096
max_steps: 2000              # matches the paired MaxEnt 2k math run
num_generations: 16          # paper setting
num_train_epochs: 5
use_vllm: true
vllm_url: http://localhost:29525
output_dir: var/data/Qwen2.5-7B-Open-R1-GRPO-math-2k
overwrite_output_dir: true
per_device_eval_batch_size: 8
per_device_train_batch_size: 1   # with grad accum 64 -> effective batch 128 (paper)
push_to_hub: true
report_to:
- wandb
wandb_project: huggingface
wandb_entity: ogd3-princeton-university
reward_funcs:
- pure_accuracy_math
reward_weights:
- 1

# Reverse‑KL weight β used inside GRPO update
init_kl_coeff: 0.04        # MaxEnt/metrics path reads this alias
init_kl_coef: 0.04         # TRL field that seeds the KL controller/beta
kl_penalty_beta: 0.04      # Extra TRL alias used by some releases
kl_target:        0.07
kl_horizon:       500
kl_ctl_step_size: 1.0

# Misc GRPO knobs (kept consistent with MaxEnt recipe)
max_grad_norm: 0.15
clip_range: 0.05
save_strategy: steps
save_steps: 50
evaluation_strategy: steps
eval_steps: 25
save_total_limit: 1000
seed: 42
warmup_ratio: 0.2
